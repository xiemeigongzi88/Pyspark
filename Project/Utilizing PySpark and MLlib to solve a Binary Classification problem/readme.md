# Utilizing PySpark and MLlib to solve a Binary Classification problem 
  PySpark is just a Python wrapper around Apache Spark which is written in Scala programming language.
  
  PySpark is an all-in-one ecosystem which can handle the aggressive requirements with its MLlib, Structured data processing API, GraphX will definite of help.
  
  Hadoop data can be processed with PySpark, so it will not be of any problem.
  
  PySpark is a great language for data scientists to learn because it enables scalable analysis and ML pipelines. If you're already familiar with Python and Pandas, then much of your knowledge can be applied to Spark. I've shown how to perform some common operations with PySpark to bootstrap the learning process. 
  
  Apache Spark offers a Machine Learning API called MLlib. PySpark has this machine learning API in Python as well. It supports different kind of algorithms. 

## Databricks Code: https://community.cloud.databricks.com/?o=1596259945501472#notebook/1525786715330318/command/1525786715330326

## Target:  Finishing  Logistic Regression, Decision Tree, Random Forest,  and Gradient-Boosted with PySpark

  Dataset: https://www.kaggle.com/rouseguy/bankbalanced/data

## Steps: 
  Exploratory data analysis
  Preparing Data for Machine Learning
  Logistic Regression Model
  Decision Tree Classifier
  Random Forest Classifier
  Gradient-Boosted Tree Classifier

## Summary: 
  Learning how to build a binary classification application using PySpark and MLlib Pipelines API.
  
  I just got the fun from the hidden insights of data. And this project was inspired by the project “Machine Learning with PySpark and MLlib — Solving a Binary Classification Problem”. https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa
