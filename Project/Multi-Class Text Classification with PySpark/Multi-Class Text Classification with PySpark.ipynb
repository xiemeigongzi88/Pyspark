{"cells":[{"cell_type":"code","source":["from pyspark.sql import SQLContext\nfrom pyspark import SparkContext\n\nsqlContext = SQLContext(sc)\ndata = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/FileStore/tables/pyspark_learning/test/train.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["drop_list = ['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\ndata = data.select([column for column in data.columns if column not in drop_list])\ndata.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+\n      Category|            Descript|\n+--------------+--------------------+\n      WARRANTS|      WARRANT ARREST|\nOTHER OFFENSES|TRAFFIC VIOLATION...|\nOTHER OFFENSES|TRAFFIC VIOLATION...|\n LARCENY/THEFT|GRAND THEFT FROM ...|\n LARCENY/THEFT|GRAND THEFT FROM ...|\n+--------------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["data.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Category: string (nullable = true)\n-- Descript: string (nullable = true)\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Top 20 crime categories:\nfrom pyspark.sql.functions import col\ndata.groupBy(\"Category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------+\n            Category| count|\n+--------------------+------+\n       LARCENY/THEFT|174900|\n      OTHER OFFENSES|126182|\n        NON-CRIMINAL| 92304|\n             ASSAULT| 76876|\n       DRUG/NARCOTIC| 53971|\n       VEHICLE THEFT| 53781|\n           VANDALISM| 44725|\n            WARRANTS| 42214|\n            BURGLARY| 36755|\n      SUSPICIOUS OCC| 31414|\n      MISSING PERSON| 25989|\n             ROBBERY| 23000|\n               FRAUD| 16679|\nFORGERY/COUNTERFE...| 10609|\n     SECONDARY CODES|  9985|\n         WEAPON LAWS|  8555|\n        PROSTITUTION|  7484|\n            TRESPASS|  7326|\n     STOLEN PROPERTY|  4540|\nSEX OFFENSES FORC...|  4388|\n+--------------------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Top 20 crime descriptions:\n\ndata.groupBy(\"Descript\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n            Descript|count|\n+--------------------+-----+\nGRAND THEFT FROM ...|60022|\n       LOST PROPERTY|31729|\n             BATTERY|27441|\n   STOLEN AUTOMOBILE|26897|\nDRIVERS LICENSE, ...|26839|\n      WARRANT ARREST|23754|\nSUSPICIOUS OCCURR...|21891|\nAIDED CASE, MENTA...|21497|\nPETTY THEFT FROM ...|19771|\nMALICIOUS MISCHIE...|17789|\n   TRAFFIC VIOLATION|16471|\nPETTY THEFT OF PR...|16196|\nMALICIOUS MISCHIE...|15957|\nTHREATS AGAINST LIFE|14716|\n      FOUND PROPERTY|12146|\nENROUTE TO OUTSID...|11470|\nGRAND THEFT OF PR...|11010|\nPOSSESSION OF NAR...|10050|\nPETTY THEFT FROM ...|10029|\nPETTY THEFT SHOPL...| 9571|\n+--------------------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Model Pipeline\nfrom pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\nfrom pyspark.ml.classification import LogisticRegression\n# regular expression tokenizer\nregexTokenizer = RegexTokenizer(inputCol=\"Descript\", outputCol=\"words\", pattern=\"\\\\W\")\n# stop words\nadd_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# bag of words count\ncountVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nlabel_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n# Fit the pipeline to training documents.\npipelineFit = pipeline.fit(data)\ndataset = pipelineFit.transform(data)\ndataset.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n      Category|            Descript|               words|            filtered|            features|label|\n+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n      WARRANTS|      WARRANT ARREST|   [warrant, arrest]|   [warrant, arrest]|(809,[17,32],[1.0...|  7.0|\nOTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(809,[11,17,35],[...|  1.0|\nOTHER OFFENSES|TRAFFIC VIOLATION...|[traffic, violati...|[traffic, violati...|(809,[11,17,35],[...|  1.0|\n LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, fr...|(809,[0,2,3,4,6],...|  0.0|\n LARCENY/THEFT|GRAND THEFT FROM ...|[grand, theft, fr...|[grand, theft, fr...|(809,[0,2,3,4,6],...|  0.0|\n+--------------+--------------------+--------------------+--------------------+--------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Model Training and Evaluation\n# set seed for reproducibility\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 614666\nTest Dataset Count: 263383\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nlrModel = lr.fit(trainingData)\npredictions = lrModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------+-------------+------------------------------+-----+----------+\n                      Descript|     Category|                   probability|label|prediction|\n+------------------------------+-------------+------------------------------+-----+----------+\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8711581002180693,0.02115...|  0.0|       0.0|\n+------------------------------+-------------+------------------------------+-----+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: 0.9725282146509521</div>"]}}],"execution_count":11},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\npipelineFit = pipeline.fit(data)\ndataset = pipelineFit.transform(data)\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nlr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["predictions = lrModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------+-------------+------------------------------+-----+----------+\n                      Descript|     Category|                   probability|label|prediction|\n+------------------------------+-------------+------------------------------+-----+----------+\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\nTHEFT, BICYCLE, &lt;$50, NO SE...|LARCENY/THEFT|[0.8730538827818622,0.02078...|  0.0|       0.0|\n+------------------------------+-------------+------------------------------+-----+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: 0.9722954523853476</div>"]}}],"execution_count":14},{"cell_type":"code","source":["pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\npipelineFit = pipeline.fit(data)\ndataset = pipelineFit.transform(data)\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nlr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n             .build())\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, \\\n                    estimatorParamMaps=paramGrid, \\\n                    evaluator=evaluator, \\\n                    numFolds=5)\ncvModel = cv.fit(trainingData)\n\npredictions = cvModel.transform(testData)\n# Evaluate best model\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\nOut[18]: 0.9919124901837848</div>"]}}],"execution_count":15},{"cell_type":"code","source":["# Naive Bayes\n\nfrom pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(smoothing=1)\nmodel = nb.fit(trainingData)\npredictions = model.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------+-------------+------------------------------+-----+----------+\n                    Descript|     Category|                   probability|label|prediction|\n+----------------------------+-------------+------------------------------+-----+----------+\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\nPETTY THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.9999999999837754,1.54986...|  0.0|       0.0|\n+----------------------------+-------------+------------------------------+-----+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: 0.9939847228864086</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Random Forest\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"label\", \\\n                            featuresCol=\"features\", \\\n                            numTrees = 100, \\\n                            maxDepth = 4, \\\n                            maxBins = 32)\n# Train model with Training Data\nrfModel = rf.fit(trainingData)\npredictions = rfModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------+-------------+------------------------------+-----+----------+\n                    Descript|     Category|                   probability|label|prediction|\n+----------------------------+-------------+------------------------------+-----+----------+\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\nGRAND THEFT FROM LOCKED AUTO|LARCENY/THEFT|[0.6145065348252539,0.06668...|  0.0|       0.0|\n+----------------------------+-------------+------------------------------+-----+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: 0.7401619893685347</div>"]}}],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"Multi-Class Text Classification with PySpark","notebookId":1525786715330287},"nbformat":4,"nbformat_minor":0}
